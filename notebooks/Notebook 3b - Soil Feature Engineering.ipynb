{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd0ff67",
   "metadata": {},
   "source": [
    "# Notebook 3b - Soil Type Engineering\n",
    "\n",
    "In this notebook, we use soil type features to engineer new features using interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd70e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for testing changes to this notebook quickly\n",
    "RANDOM_SEED = 0\n",
    "NUM_FOLDS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549a23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pyarrow\n",
    "import gc\n",
    "\n",
    "# Model evaluation\n",
    "from functools import partial\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf981568",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d0b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode soil type\n",
    "def categorical_encoding(input_df):\n",
    "    data = input_df.copy()\n",
    "    data['Soil_Type'] = 0\n",
    "    soil_features = list()\n",
    "    for i in range(1,41):\n",
    "        data['Soil_Type'] += i*data[f'Soil_Type{i}']\n",
    "        soil_features.append(f'Soil_Type{i}')\n",
    "    nonsoil_features = [x for x in data.columns if x not in soil_features]\n",
    "    return data[nonsoil_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a25690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 239 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load original data\n",
    "original = categorical_encoding(pd.read_feather('../data/original.feather'))\n",
    "\n",
    "# Label Encode\n",
    "old_encoder = LabelEncoder()\n",
    "original[\"Cover_Type\"] = old_encoder.fit_transform(original[\"Cover_Type\"])\n",
    "y_train = original['Cover_Type'].iloc[:15119]\n",
    "y_test = original['Cover_Type'].iloc[15119:]\n",
    "\n",
    "# Get feature columns\n",
    "features = [x for x in original.columns if x not in ['Id','Cover_Type']]\n",
    "\n",
    "# Data structures for summary scores\n",
    "bagging_scores = list()\n",
    "extratrees_scores = list()\n",
    "adaboost_scores = list()\n",
    "random_scores = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66116f",
   "metadata": {},
   "source": [
    "# Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef3fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_original(sklearn_model, processing = None):\n",
    "    \n",
    "    # Original Training/Test Split\n",
    "    X_temp = original[features].iloc[:15119]\n",
    "    X_test = original[features].iloc[15119:]\n",
    "    y_temp = original['Cover_Type'].iloc[:15119]\n",
    "    y_test = original['Cover_Type'].iloc[15119:]\n",
    "    \n",
    "    # Feature Engineering\n",
    "    if processing:\n",
    "        X_temp = processing(X_temp)\n",
    "        X_test = processing(X_test)\n",
    "        \n",
    "    # Store the out-of-fold predictions\n",
    "    test_preds = np.zeros((X_test.shape[0],7))\n",
    "    oof_preds = np.zeros((X_temp.shape[0],))\n",
    "    scores, times = np.zeros(NUM_FOLDS), np.zeros(NUM_FOLDS)\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X_temp,y_temp)):\n",
    "       \n",
    "        # Training and Validation Sets\n",
    "        X_train, X_valid = X_temp.iloc[train_idx], X_temp.iloc[valid_idx]\n",
    "        y_train, y_valid = y_temp.iloc[train_idx], y_temp.iloc[valid_idx]\n",
    "        \n",
    "        # Create model\n",
    "        start = time.time()\n",
    "        model = clone(sklearn_model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # validation and test predictions\n",
    "        valid_preds = np.ravel(model.predict(X_valid))\n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "        test_preds += model.predict_proba(X_test)\n",
    "        \n",
    "        # Save scores and times\n",
    "        scores[fold] = accuracy_score(y_valid, valid_preds)\n",
    "        end = time.time()\n",
    "        times[fold] = end-start\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    test_preds = np.argmax(test_preds, axis = 1)\n",
    "    test_score = accuracy_score(y_test, test_preds)\n",
    "    print('\\n'+model.__class__.__name__)\n",
    "    print(\"Train Accuracy:\", round(scores.mean(), 5))\n",
    "    print('Test Accuracy:', round(test_score, 5))\n",
    "    print(f'Training Time: {round(times.sum(), 2)}s')\n",
    "    \n",
    "    return scores.mean(), oof_preds, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78094bd",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "We use the following 4 models from the scikit-learn library:\n",
    "\n",
    "1. AdaBoost \n",
    "2. ExtraTrees\n",
    "3. Bagging\n",
    "4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28bc0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Classifier\n",
    "adaboost = AdaBoostClassifier(\n",
    "    base_estimator = DecisionTreeClassifier(\n",
    "        splitter = 'random',\n",
    "        random_state = RANDOM_SEED,\n",
    "    ),\n",
    "    random_state = RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# ExtraTrees Classifier\n",
    "extratrees = ExtraTreesClassifier(\n",
    "    n_jobs = -1,\n",
    "    random_state = RANDOM_SEED,\n",
    "    max_features = None,\n",
    ")\n",
    "\n",
    "# Bagging Classifier\n",
    "bagging = BaggingClassifier(\n",
    "    base_estimator = DecisionTreeClassifier(\n",
    "        splitter = 'random',\n",
    "        random_state = RANDOM_SEED,\n",
    "    ),\n",
    "    n_jobs = -1,\n",
    "    random_state = RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Random Forest Classifier\n",
    "randomforest = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    random_state = RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30059f",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d433f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.78596\n",
      "Test Accuracy: 0.76229\n",
      "Training Time: 3.68s\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88538\n",
      "Test Accuracy: 0.78206\n",
      "Training Time: 37.48s\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85006\n",
      "Test Accuracy: 0.75982\n",
      "Training Time: 21.03s\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86454\n",
      "Test Accuracy: 0.74822\n",
      "Training Time: 35.33s\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Baseline', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# ExtraTrees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Baseline', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Baseline', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "cv_score, oof_preds, test_score = train_original(randomforest)\n",
    "\n",
    "random_scores.append((\n",
    "    'Baseline', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a34bef",
   "metadata": {},
   "source": [
    "# Categorial Feature Interactions\n",
    "\n",
    "We test out the following interactions:\n",
    "\n",
    "1. Climatic Zone and Wilderness Area\n",
    "2. Geologic Zone and Wilderness Area\n",
    "3. Surface Cover and Wilderness Area\n",
    "4. Rock Size and Wilderness Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11a9ce",
   "metadata": {},
   "source": [
    "## 1. Climatic Zone and Wilderness Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06bab40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def climatic_zone_original(input_df):\n",
    "    code = {\n",
    "        1:2702,2:2703,3:2704,4:2705,5:2706,6:2717,7:3501,8:3502,9:4201,\n",
    "        10:4703,11:4704,12:4744,13:4758,14:5101,15:5151,16:6101,17:6102,\n",
    "        18:6731,19:7101,20:7102,21:7103,22:7201,23:7202,24:7700,25:7701,\n",
    "        26:7702,27:7709,28:7710,29:7745,30:7746,31:7755,32:7756,33:7757,\n",
    "        34:7790,35:8703,36:8707,37:8708,38:8771,39:8772,40:8776\n",
    "    }\n",
    "    df = input_df.copy()\n",
    "    df['Climatic_Zone'] = input_df['Soil_Type'].apply(lambda x: int(str(code[x])[0]))\n",
    "    return df\n",
    "\n",
    "def wilderness_climatic(input_df, drop = False):\n",
    "    data = climatic_zone_original(input_df)\n",
    "    df = input_df.copy()\n",
    "    df['Climate_Area1'] = df['Wilderness_Area1']*data['Climatic_Zone'] \n",
    "    df['Climate_Area2'] = df['Wilderness_Area2']*data['Climatic_Zone'] \n",
    "    df['Climate_Area3'] = df['Wilderness_Area3']*data['Climatic_Zone'] \n",
    "    df['Climate_Area4'] = df['Wilderness_Area4']*data['Climatic_Zone'] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a6b0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.78868\n",
      "Test Accuracy: 0.75762\n",
      "Training Time: 3.43s\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88524\n",
      "Test Accuracy: 0.78313\n",
      "Training Time: 36.32s\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85297\n",
      "Test Accuracy: 0.76035\n",
      "Training Time: 21.58s\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86441\n",
      "Test Accuracy: 0.7501\n",
      "Training Time: 35.42s\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost, wilderness_climatic)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Wild_Clim', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# ExtraTrees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees, wilderness_climatic)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Wild_Clim', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging, wilderness_climatic)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Wild_Clim', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# RandomForest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest, wilderness_climatic)\n",
    "\n",
    "random_scores.append((\n",
    "    'Wild_Clim', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffabc2a",
   "metadata": {},
   "source": [
    "## 2. Geologic Zone and Wilderness Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70ff6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geologic_zone_original(input_df):\n",
    "    code = {\n",
    "        1:2702,2:2703,3:2704,4:2705,5:2706,6:2717,7:3501,8:3502,9:4201,\n",
    "        10:4703,11:4704,12:4744,13:4758,14:5101,15:5151,16:6101,17:6102,\n",
    "        18:6731,19:7101,20:7102,21:7103,22:7201,23:7202,24:7700,25:7701,\n",
    "        26:7702,27:7709,28:7710,29:7745,30:7746,31:7755,32:7756,33:7757,\n",
    "        34:7790,35:8703,36:8707,37:8708,38:8771,39:8772,40:8776\n",
    "    }\n",
    "    df = input_df.copy()\n",
    "    df['Geologic_Zone'] = input_df['Soil_Type'].apply(lambda x: int(str(code[x])[1]))\n",
    "    return df\n",
    "\n",
    "def wilderness_geologic(input_df, drop = False):\n",
    "    data = geologic_zone_original(input_df)\n",
    "    df = input_df.copy()\n",
    "    df['Geologic_Area1'] = df['Wilderness_Area1']*data['Geologic_Zone'] \n",
    "    df['Geologic_Area2'] = df['Wilderness_Area2']*data['Geologic_Zone']  \n",
    "    df['Geologic_Area3'] = df['Wilderness_Area3']*data['Geologic_Zone'] \n",
    "    df['Geologic_Area4'] = df['Wilderness_Area4']*data['Geologic_Zone'] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c3184d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.7906\n",
      "Test Accuracy: 0.76019\n",
      "Training Time: 3.52s\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88339\n",
      "Test Accuracy: 0.78244\n",
      "Training Time: 35.59s\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85336\n",
      "Test Accuracy: 0.75781\n",
      "Training Time: 19.68s\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.8654\n",
      "Test Accuracy: 0.75015\n",
      "Training Time: 34.45s\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost, wilderness_geologic)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Wild_Geo', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# ExtraTrees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees, wilderness_geologic)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Wild_Geo', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging, wilderness_geologic)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Wild_Geo', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# RandomForest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest, wilderness_geologic)\n",
    "\n",
    "random_scores.append((\n",
    "    'Wild_Geo', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b496275f",
   "metadata": {},
   "source": [
    "## 3. Surface Cover and Wilderness Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6e37247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_cover_original(input_df):\n",
    "    # Group IDs\n",
    "    no_desc = [7,8,14,15,16,17,19,20,21,23,35]\n",
    "    stony = [6,12]\n",
    "    very_stony = [2,9,18,26]\n",
    "    extremely_stony = [1,22,24,25,27,28,29,30,31,32,33,34,36,37,38,39,40]\n",
    "    rubbly = [3,4,5,10,11,13]\n",
    "\n",
    "    # Create dictionary\n",
    "    surface_cover = {i:0 for i in no_desc}\n",
    "    surface_cover.update({i:1 for i in stony})\n",
    "    surface_cover.update({i:2 for i in very_stony})\n",
    "    surface_cover.update({i:3 for i in extremely_stony})\n",
    "    surface_cover.update({i:4 for i in rubbly})\n",
    "    \n",
    "    # Create Feature\n",
    "    df = input_df.copy()\n",
    "    df['Surface_Cover'] = input_df['Soil_Type'].apply(lambda x: surface_cover[x])\n",
    "    return df\n",
    "\n",
    "def wilderness_surface(input_df, drop = False):\n",
    "    data = surface_cover_original(input_df)\n",
    "    df = input_df.copy()\n",
    "    df['Surface_Area1'] = df['Wilderness_Area1']*data['Surface_Cover'] \n",
    "    df['Surface_Area2'] = df['Wilderness_Area2']*data['Surface_Cover']   \n",
    "    df['Surface_Area3'] = df['Wilderness_Area3']*data['Surface_Cover']  \n",
    "    df['Surface_Area4'] = df['Wilderness_Area4']*data['Surface_Cover'] \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c07cd25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.78623\n",
      "Test Accuracy: 0.75803\n",
      "Training Time: 3.56s\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88432\n",
      "Test Accuracy: 0.78333\n",
      "Training Time: 36.76s\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85336\n",
      "Test Accuracy: 0.75816\n",
      "Training Time: 20.64s\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86487\n",
      "Test Accuracy: 0.75105\n",
      "Training Time: 37.42s\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost, wilderness_surface)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Wild_Surf', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# ExtraTrees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees, wilderness_surface)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Wild_Surf', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging, wilderness_surface)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Wild_Surf', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# RandomForest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest, wilderness_surface)\n",
    "\n",
    "random_scores.append((\n",
    "    'Wild_Surf', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be1e18",
   "metadata": {},
   "source": [
    "## 4. Rock Size and Wilderness Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f501612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rock_size_original(input_df):\n",
    "    \n",
    "    # Group IDs\n",
    "    no_desc = [7,8,14,15,16,17,19,20,21,23,35]\n",
    "    stones = [1,2,6,9,12,18,24,25,26,27,28,29,30,31,32,33,34,36,37,38,39,40]\n",
    "    boulders = [22]\n",
    "    rubble = [3,4,5,10,11,13]\n",
    "\n",
    "    # Create dictionary\n",
    "    rock_size = {i:0 for i in no_desc}\n",
    "    rock_size.update({i:1 for i in stones})\n",
    "    rock_size.update({i:2 for i in boulders})\n",
    "    rock_size.update({i:3 for i in rubble})\n",
    "    \n",
    "    df = input_df.copy()\n",
    "    df['Rock_Size'] = input_df['Soil_Type'].apply(lambda x: rock_size[x])\n",
    "    return df\n",
    "\n",
    "def wilderness_rocksize(input_df, drop = False):\n",
    "    data = rock_size_original(input_df)\n",
    "    df = input_df.copy()\n",
    "    df['Rock_Area1'] = df['Wilderness_Area1']*data['Rock_Size'] \n",
    "    df['Rock_Area2'] = df['Wilderness_Area2']*data['Rock_Size']   \n",
    "    df['Rock_Area3'] = df['Wilderness_Area3']*data['Rock_Size']  \n",
    "    df['Rock_Area4'] = df['Wilderness_Area4']*data['Rock_Size']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feedc1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.78729\n",
      "Test Accuracy: 0.75985\n",
      "Training Time: 3.67s\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88591\n",
      "Test Accuracy: 0.78314\n",
      "Training Time: 39.85s\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85145\n",
      "Test Accuracy: 0.75864\n",
      "Training Time: 23.36s\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86606\n",
      "Test Accuracy: 0.75107\n",
      "Training Time: 37.14s\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost, wilderness_rocksize)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Wild_Rock', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# ExtraTrees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees, wilderness_rocksize)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Wild_Rock', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging, wilderness_rocksize)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Wild_Rock', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "# RandomForest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest, wilderness_rocksize)\n",
    "\n",
    "random_scores.append((\n",
    "    'Wild_Rock', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f71fe",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "These probably require more testing (permutation importance, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d53705f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>holdout</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>recall_3</th>\n",
       "      <th>recall_4</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.785965</td>\n",
       "      <td>0.762291</td>\n",
       "      <td>0.674537</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.723020</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.878704</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.924074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wild_Surf</td>\n",
       "      <td>0.786228</td>\n",
       "      <td>0.758028</td>\n",
       "      <td>0.674074</td>\n",
       "      <td>0.615278</td>\n",
       "      <td>0.733210</td>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.881019</td>\n",
       "      <td>0.752315</td>\n",
       "      <td>0.927315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wild_Rock</td>\n",
       "      <td>0.787288</td>\n",
       "      <td>0.759849</td>\n",
       "      <td>0.675463</td>\n",
       "      <td>0.607870</td>\n",
       "      <td>0.732747</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>0.890278</td>\n",
       "      <td>0.757870</td>\n",
       "      <td>0.937037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wild_Clim</td>\n",
       "      <td>0.788677</td>\n",
       "      <td>0.757618</td>\n",
       "      <td>0.684259</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>0.738768</td>\n",
       "      <td>0.907870</td>\n",
       "      <td>0.887963</td>\n",
       "      <td>0.757407</td>\n",
       "      <td>0.930556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wild_Geo</td>\n",
       "      <td>0.790596</td>\n",
       "      <td>0.760190</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.613426</td>\n",
       "      <td>0.736915</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.765741</td>\n",
       "      <td>0.931481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features  cv_score   holdout  recall_0  recall_1  recall_2  recall_3  \\\n",
       "0   Baseline  0.785965  0.762291  0.674537  0.637500  0.723020  0.918519   \n",
       "3  Wild_Surf  0.786228  0.758028  0.674074  0.615278  0.733210  0.920370   \n",
       "4  Wild_Rock  0.787288  0.759849  0.675463  0.607870  0.732747  0.909722   \n",
       "1  Wild_Clim  0.788677  0.757618  0.684259  0.613889  0.738768  0.907870   \n",
       "2   Wild_Geo  0.790596  0.760190  0.659722  0.613426  0.736915  0.930556   \n",
       "\n",
       "   recall_4  recall_5  recall_6  \n",
       "0  0.878704  0.745370  0.924074  \n",
       "3  0.881019  0.752315  0.927315  \n",
       "4  0.890278  0.757870  0.937037  \n",
       "1  0.887963  0.757407  0.930556  \n",
       "2  0.896296  0.765741  0.931481  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost\n",
    "pd.DataFrame.from_records(\n",
    "    data = adaboost_scores,\n",
    "    columns = ['features','cv_score','holdout','recall_0', 'recall_1','recall_2','recall_3','recall_4','recall_5','recall_6']\n",
    ").sort_values('cv_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "634d89ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>holdout</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>recall_3</th>\n",
       "      <th>recall_4</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wild_Geo</td>\n",
       "      <td>0.883392</td>\n",
       "      <td>0.782445</td>\n",
       "      <td>0.785648</td>\n",
       "      <td>0.738889</td>\n",
       "      <td>0.856878</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.959259</td>\n",
       "      <td>0.900926</td>\n",
       "      <td>0.971759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wild_Surf</td>\n",
       "      <td>0.884319</td>\n",
       "      <td>0.783328</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.737037</td>\n",
       "      <td>0.855952</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.958796</td>\n",
       "      <td>0.904630</td>\n",
       "      <td>0.975463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wild_Clim</td>\n",
       "      <td>0.885244</td>\n",
       "      <td>0.783130</td>\n",
       "      <td>0.791204</td>\n",
       "      <td>0.740278</td>\n",
       "      <td>0.856878</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.961574</td>\n",
       "      <td>0.902315</td>\n",
       "      <td>0.973611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.885377</td>\n",
       "      <td>0.782060</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.861510</td>\n",
       "      <td>0.971759</td>\n",
       "      <td>0.961111</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.972685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wild_Rock</td>\n",
       "      <td>0.885906</td>\n",
       "      <td>0.783145</td>\n",
       "      <td>0.790278</td>\n",
       "      <td>0.742593</td>\n",
       "      <td>0.861047</td>\n",
       "      <td>0.971296</td>\n",
       "      <td>0.959259</td>\n",
       "      <td>0.903704</td>\n",
       "      <td>0.973148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features  cv_score   holdout  recall_0  recall_1  recall_2  recall_3  \\\n",
       "2   Wild_Geo  0.883392  0.782445  0.785648  0.738889  0.856878  0.970370   \n",
       "3  Wild_Surf  0.884319  0.783328  0.784722  0.737037  0.855952  0.973611   \n",
       "1  Wild_Clim  0.885244  0.783130  0.791204  0.740278  0.856878  0.970833   \n",
       "0   Baseline  0.885377  0.782060  0.787500  0.737500  0.861510  0.971759   \n",
       "4  Wild_Rock  0.885906  0.783145  0.790278  0.742593  0.861047  0.971296   \n",
       "\n",
       "   recall_4  recall_5  recall_6  \n",
       "2  0.959259  0.900926  0.971759  \n",
       "3  0.958796  0.904630  0.975463  \n",
       "1  0.961574  0.902315  0.973611  \n",
       "0  0.961111  0.905556  0.972685  \n",
       "4  0.959259  0.903704  0.973148  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "pd.DataFrame.from_records(\n",
    "    data = extratrees_scores,\n",
    "    columns = ['features','cv_score','holdout','recall_0', 'recall_1','recall_2','recall_3','recall_4','recall_5','recall_6']\n",
    ").sort_values('cv_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d38c1a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>holdout</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>recall_3</th>\n",
       "      <th>recall_4</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.850057</td>\n",
       "      <td>0.759820</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.819824</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.954630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wild_Rock</td>\n",
       "      <td>0.851446</td>\n",
       "      <td>0.758642</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.657870</td>\n",
       "      <td>0.834182</td>\n",
       "      <td>0.964352</td>\n",
       "      <td>0.937963</td>\n",
       "      <td>0.839352</td>\n",
       "      <td>0.957870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wild_Clim</td>\n",
       "      <td>0.852967</td>\n",
       "      <td>0.760347</td>\n",
       "      <td>0.769444</td>\n",
       "      <td>0.664815</td>\n",
       "      <td>0.836035</td>\n",
       "      <td>0.964352</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.832870</td>\n",
       "      <td>0.961574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wild_Geo</td>\n",
       "      <td>0.853363</td>\n",
       "      <td>0.757806</td>\n",
       "      <td>0.766204</td>\n",
       "      <td>0.668981</td>\n",
       "      <td>0.841593</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.959259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wild_Surf</td>\n",
       "      <td>0.853364</td>\n",
       "      <td>0.758156</td>\n",
       "      <td>0.781481</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.842057</td>\n",
       "      <td>0.964352</td>\n",
       "      <td>0.936111</td>\n",
       "      <td>0.831481</td>\n",
       "      <td>0.956944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features  cv_score   holdout  recall_0  recall_1  recall_2  recall_3  \\\n",
       "0   Baseline  0.850057  0.759820  0.775000  0.672222  0.819824  0.958333   \n",
       "4  Wild_Rock  0.851446  0.758642  0.768519  0.657870  0.834182  0.964352   \n",
       "1  Wild_Clim  0.852967  0.760347  0.769444  0.664815  0.836035  0.964352   \n",
       "2   Wild_Geo  0.853363  0.757806  0.766204  0.668981  0.841593  0.966667   \n",
       "3  Wild_Surf  0.853364  0.758156  0.781481  0.661111  0.842057  0.964352   \n",
       "\n",
       "   recall_4  recall_5  recall_6  \n",
       "0  0.939815  0.830556  0.954630  \n",
       "4  0.937963  0.839352  0.957870  \n",
       "1  0.941667  0.832870  0.961574  \n",
       "2  0.937500  0.833333  0.959259  \n",
       "3  0.936111  0.831481  0.956944  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging Classifier\n",
    "pd.DataFrame.from_records(\n",
    "    data = bagging_scores,\n",
    "    columns = ['features','cv_score','holdout','recall_0', 'recall_1','recall_2','recall_3','recall_4','recall_5','recall_6']\n",
    ").sort_values('cv_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a56dbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>holdout</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>recall_3</th>\n",
       "      <th>recall_4</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wild_Clim</td>\n",
       "      <td>0.864409</td>\n",
       "      <td>0.750103</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.830014</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.954630</td>\n",
       "      <td>0.867130</td>\n",
       "      <td>0.964352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.748216</td>\n",
       "      <td>0.765741</td>\n",
       "      <td>0.695370</td>\n",
       "      <td>0.824456</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.871759</td>\n",
       "      <td>0.968056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wild_Surf</td>\n",
       "      <td>0.864873</td>\n",
       "      <td>0.751052</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.690278</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.969444</td>\n",
       "      <td>0.952315</td>\n",
       "      <td>0.876852</td>\n",
       "      <td>0.963426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wild_Geo</td>\n",
       "      <td>0.865402</td>\n",
       "      <td>0.750151</td>\n",
       "      <td>0.769444</td>\n",
       "      <td>0.701852</td>\n",
       "      <td>0.827698</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>0.868519</td>\n",
       "      <td>0.965278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wild_Rock</td>\n",
       "      <td>0.866063</td>\n",
       "      <td>0.751075</td>\n",
       "      <td>0.775926</td>\n",
       "      <td>0.697222</td>\n",
       "      <td>0.825845</td>\n",
       "      <td>0.973148</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>0.871296</td>\n",
       "      <td>0.964815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features  cv_score   holdout  recall_0  recall_1  recall_2  recall_3  \\\n",
       "1  Wild_Clim  0.864409  0.750103  0.766667  0.695833  0.830014  0.972222   \n",
       "0   Baseline  0.864542  0.748216  0.765741  0.695370  0.824456  0.970833   \n",
       "3  Wild_Surf  0.864873  0.751052  0.775000  0.690278  0.826772  0.969444   \n",
       "2   Wild_Geo  0.865402  0.750151  0.769444  0.701852  0.827698  0.970833   \n",
       "4  Wild_Rock  0.866063  0.751075  0.775926  0.697222  0.825845  0.973148   \n",
       "\n",
       "   recall_4  recall_5  recall_6  \n",
       "1  0.954630  0.867130  0.964352  \n",
       "0  0.955556  0.871759  0.968056  \n",
       "3  0.952315  0.876852  0.963426  \n",
       "2  0.954167  0.868519  0.965278  \n",
       "4  0.954167  0.871296  0.964815  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "pd.DataFrame.from_records(\n",
    "    data = random_scores,\n",
    "    columns = ['features','cv_score','holdout','recall_0', 'recall_1','recall_2','recall_3','recall_4','recall_5','recall_6']\n",
    ").sort_values('cv_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
