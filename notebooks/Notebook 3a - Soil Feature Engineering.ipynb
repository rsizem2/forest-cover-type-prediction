{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe400ca5",
   "metadata": {},
   "source": [
    "# Notebook 3b - Breakdown Soil Type\n",
    "\n",
    "In this notebook, we test out breaking down the soil-type features using domain knowledge and their descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c15cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for testing changes to this notebook quickly\n",
    "RANDOM_SEED = 0\n",
    "NUM_FOLDS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a988bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pyarrow\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "\n",
    "# Model evaluation\n",
    "from functools import partial\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.inspection import partial_dependence, permutation_importance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7fc4cc",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d54a836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 484 ms\n",
      "Wall time: 76 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load original data\n",
    "original = pd.read_feather('../data/original.feather')\n",
    "\n",
    "# Label Encode\n",
    "old_encoder = LabelEncoder()\n",
    "original[\"Cover_Type\"] = old_encoder.fit_transform(original[\"Cover_Type\"])\n",
    "y_train = original['Cover_Type'].iloc[:15119]\n",
    "y_test = original['Cover_Type'].iloc[15119:]\n",
    "\n",
    "# Get feature columns\n",
    "features = [x for x in original.columns if x not in ['Id','Cover_Type']]\n",
    "\n",
    "# Data structures for summary scores\n",
    "baseline = defaultdict(dict)\n",
    "bagging_scores = list()\n",
    "extratrees_scores = list()\n",
    "adaboost_scores = list()\n",
    "random_scores = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4b2b8",
   "metadata": {},
   "source": [
    "# Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45bf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_original(sklearn_model, processing = None):\n",
    "    \n",
    "    # Original Training/Test Split\n",
    "    X_temp = original[features].iloc[:15119]\n",
    "    X_test = original[features].iloc[15119:]\n",
    "    y_temp = original['Cover_Type'].iloc[:15119]\n",
    "    y_test = original['Cover_Type'].iloc[15119:]\n",
    "    \n",
    "    # Feature Engineering\n",
    "    if processing:\n",
    "        X_temp = processing(X_temp)\n",
    "        X_test = processing(X_test)\n",
    "        \n",
    "    # Store the out-of-fold predictions\n",
    "    test_preds = np.zeros((X_test.shape[0],7))\n",
    "    oof_preds = np.zeros((X_temp.shape[0],))\n",
    "    scores, times = np.zeros(NUM_FOLDS), np.zeros(NUM_FOLDS)\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X_temp,y_temp)):\n",
    "       \n",
    "        # Training and Validation Sets\n",
    "        X_train, X_valid = X_temp.iloc[train_idx], X_temp.iloc[valid_idx]\n",
    "        y_train, y_valid = y_temp.iloc[train_idx], y_temp.iloc[valid_idx]\n",
    "        \n",
    "        # Create model\n",
    "        start = time.time()\n",
    "        model = clone(sklearn_model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # validation and test predictions\n",
    "        valid_preds = np.ravel(model.predict(X_valid))\n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "        test_preds += model.predict_proba(X_test)\n",
    "        \n",
    "        # Save scores and times\n",
    "        scores[fold] = accuracy_score(y_valid, valid_preds)\n",
    "        end = time.time()\n",
    "        times[fold] = end-start\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    test_preds = np.argmax(test_preds, axis = 1)\n",
    "    test_score = accuracy_score(y_test, test_preds)\n",
    "    print('\\n'+model.__class__.__name__)\n",
    "    print(\"Train Accuracy:\", round(scores.mean(), 5))\n",
    "    print('Test Accuracy:', round(test_score, 5))\n",
    "    print(f'Training Time: {round(times.sum(), 2)}s')\n",
    "    \n",
    "    return scores.mean(), oof_preds, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473d0ef",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "We use the following 4 models from the scikit-learn library:\n",
    "\n",
    "1. AdaBoost \n",
    "2. ExtraTrees\n",
    "3. Bagging\n",
    "4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5d2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Classifier\n",
    "adaboost = AdaBoostClassifier(\n",
    "    base_estimator = DecisionTreeClassifier(\n",
    "        splitter = 'random',\n",
    "        random_state = RANDOM_SEED,\n",
    "    ),\n",
    "    random_state = RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# ExtraTrees Classifier\n",
    "extratrees = ExtraTreesClassifier(\n",
    "    n_jobs = -1,\n",
    "    random_state = RANDOM_SEED,\n",
    "    max_features = None,\n",
    ")\n",
    "\n",
    "# Bagging Classifier\n",
    "bagging = BaggingClassifier(\n",
    "    base_estimator = DecisionTreeClassifier(\n",
    "        splitter = 'random',\n",
    "        random_state = RANDOM_SEED,\n",
    "    ),\n",
    "    n_jobs = -1,\n",
    "    random_state = RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Random Forest Classifier\n",
    "randomforest = RandomForestClassifier(\n",
    "    n_jobs = -1,\n",
    "    random_state = RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa1731",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7370b227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.80356\n",
      "Test Accuracy: 0.75373\n",
      "Training Time: 4.32s\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88491\n",
      "Test Accuracy: 0.77808\n",
      "Training Time: 42.34s\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85581\n",
      "Test Accuracy: 0.75372\n",
      "Training Time: 27.42s\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86395\n",
      "Test Accuracy: 0.74895\n",
      "Training Time: 48.55s\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Baseline', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "baseline['Adaboost']['cv_score'] = cv_score\n",
    "baseline['Adaboost']['oof_preds'] = oof_preds\n",
    "baseline['Adaboost']['test_score'] = test_score\n",
    "\n",
    "# ExtraTrees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Baseline', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "baseline['ExtraTrees']['cv_score'] = cv_score\n",
    "baseline['ExtraTrees']['oof_preds'] = oof_preds\n",
    "baseline['ExtraTrees']['test_score'] = test_score\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Baseline', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "baseline['Bagging']['cv_score'] = cv_score\n",
    "baseline['Bagging']['oof_preds'] = oof_preds\n",
    "baseline['Bagging']['test_score'] = test_score\n",
    "\n",
    "# Random Forest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest)\n",
    "\n",
    "random_scores.append((\n",
    "    'Baseline', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "baseline['RandomForest']['cv_score'] = cv_score\n",
    "baseline['RandomForest']['oof_preds'] = oof_preds\n",
    "baseline['RandomForest']['test_score'] = test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1388cd",
   "metadata": {},
   "source": [
    "# Categorical\n",
    "\n",
    "We first test whether our models do better with or without one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3e27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode soil type\n",
    "def categorical_encoding(input_df):\n",
    "    data = input_df.copy()\n",
    "    data['Soil_Type'] = 0\n",
    "    soil_features = list()\n",
    "    for i in range(1,41):\n",
    "        data['Soil_Type'] += i*data[f'Soil_Type{i}']\n",
    "        soil_features.append(f'Soil_Type{i}')\n",
    "    nonsoil_features = [x for x in data.columns if x not in soil_features]\n",
    "    return data[nonsoil_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c801aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.78596\n",
      "Test Accuracy: 0.76229\n",
      "Training Time: 3.53s\n",
      "Train (+/-): -0.017594\n",
      "Test  (+/-): 0.008563\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88538\n",
      "Test Accuracy: 0.78206\n",
      "Training Time: 40.39s\n",
      "Train (+/-): 0.000463\n",
      "Test  (+/-): 0.003981\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85006\n",
      "Test Accuracy: 0.75982\n",
      "Training Time: 22.89s\n",
      "Train (+/-): -0.005755\n",
      "Test  (+/-): 0.006097\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86454\n",
      "Test Accuracy: 0.74822\n",
      "Training Time: 50.25s\n",
      "Train (+/-): 0.000595\n",
      "Test  (+/-): -0.000733\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost, categorical_encoding)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Categorical', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Adaboost']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Adaboost']['test_score'], 6))\n",
    "\n",
    "# ExtraTrees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees, categorical_encoding)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Categorical', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['ExtraTrees']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['ExtraTrees']['test_score'], 6))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging, categorical_encoding)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Categorical', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Bagging']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Bagging']['test_score'], 6))\n",
    "\n",
    "# Random Forest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest, categorical_encoding)\n",
    "\n",
    "random_scores.append((\n",
    "    'Categorical', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['RandomForest']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['RandomForest']['test_score'], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdd7f9a",
   "metadata": {},
   "source": [
    "# Soil Type Features\n",
    "\n",
    "We test the following features based off of the soil type descriptions from the original data:\n",
    "\n",
    "1. Climatic Zone (Ordinal)\n",
    "2. Geologic Zone (Nominal)\n",
    "3. Surface Cover (Ordinal)\n",
    "4. Rock Size (Ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01e32d",
   "metadata": {},
   "source": [
    "## Climatic Zone (Ordinal)\n",
    "\n",
    "We create a feature based on the climatic zone of the soil, which has a natural ordering:\n",
    "\n",
    "1. lower montane dry\n",
    "2. lower montane\n",
    "3. montane dry\n",
    "4. montane\n",
    "5. montane dry and montane\n",
    "6. montane and subalpine\n",
    "7. subalpine\n",
    "8. alpine\n",
    "\n",
    "However, the ordering of the soil type labels roughly follows the ordering of their respectively climatic zones, so there's a chance this feature won't be particularly informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17bc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def climatic_zone_original(input_df):\n",
    "    code = {\n",
    "        1:2702,2:2703,3:2704,4:2705,5:2706,6:2717,7:3501,8:3502,9:4201,\n",
    "        10:4703,11:4704,12:4744,13:4758,14:5101,15:5151,16:6101,17:6102,\n",
    "        18:6731,19:7101,20:7102,21:7103,22:7201,23:7202,24:7700,25:7701,\n",
    "        26:7702,27:7709,28:7710,29:7745,30:7746,31:7755,32:7756,33:7757,\n",
    "        34:7790,35:8703,36:8707,37:8708,38:8771,39:8772,40:8776\n",
    "    }\n",
    "    temp_df = categorical_encoding(input_df)\n",
    "    df = input_df.copy()\n",
    "    df['Climatic_Zone'] = temp_df['Soil_Type'].apply(lambda x: int(str(code[x])[0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6353055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.80098\n",
      "Test Accuracy: 0.75969\n",
      "Training Time: 5.72s\n",
      "Train (+/-): -0.00258\n",
      "Test  (+/-): 0.005968\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88683\n",
      "Test Accuracy: 0.78076\n",
      "Training Time: 42.9s\n",
      "Train (+/-): 0.001918\n",
      "Test  (+/-): 0.002677\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85469\n",
      "Test Accuracy: 0.75823\n",
      "Training Time: 35.65s\n",
      "Train (+/-): -0.001124\n",
      "Test  (+/-): 0.004506\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86408\n",
      "Test Accuracy: 0.74883\n",
      "Training Time: 41.28s\n",
      "Train (+/-): 0.000132\n",
      "Test  (+/-): -0.000124\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost, climatic_zone_original)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Climatic_Zone', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Adaboost']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Adaboost']['test_score'], 6))\n",
    "\n",
    "# Extra Trees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees, climatic_zone_original)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Climatic_Zone', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['ExtraTrees']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['ExtraTrees']['test_score'], 6))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging, climatic_zone_original)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Climatic_Zone', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Bagging']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Bagging']['test_score'], 6))\n",
    "\n",
    "# Random Forest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest, climatic_zone_original)\n",
    "\n",
    "random_scores.append((\n",
    "    'Climatic_Zone', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['RandomForest']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['RandomForest']['test_score'], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc64eb",
   "metadata": {},
   "source": [
    "## Geologic Zones (Nominal)\n",
    "\n",
    "This is another feature which is based on the soil type codes, but is not ordered like climatic zone.\n",
    "\n",
    "1. alluvium\n",
    "2. glacial\n",
    "3. shale\n",
    "4. sandstone\n",
    "5. mixed sedimentary\n",
    "6. unspecified in the USFS ELU Survey\n",
    "7. igneous and metamorphic\n",
    "8. volcanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "839abdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geologic_zone_original(input_df):\n",
    "    code = {\n",
    "        1:2702,2:2703,3:2704,4:2705,5:2706,6:2717,7:3501,8:3502,9:4201,\n",
    "        10:4703,11:4704,12:4744,13:4758,14:5101,15:5151,16:6101,17:6102,\n",
    "        18:6731,19:7101,20:7102,21:7103,22:7201,23:7202,24:7700,25:7701,\n",
    "        26:7702,27:7709,28:7710,29:7745,30:7746,31:7755,32:7756,33:7757,\n",
    "        34:7790,35:8703,36:8707,37:8708,38:8771,39:8772,40:8776\n",
    "    }\n",
    "    temp_df = categorical_encoding(input_df)\n",
    "    df = input_df.copy()\n",
    "    df['Geologic_Zone'] = temp_df['Soil_Type'].apply(lambda x: int(str(code[x])[1]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21439f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.79641\n",
      "Test Accuracy: 0.75359\n",
      "Training Time: 4.7s\n",
      "Train (+/-): -0.007145\n",
      "Test  (+/-): -0.00014\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88763\n",
      "Test Accuracy: 0.77757\n",
      "Training Time: 45.34s\n",
      "Train (+/-): 0.002711\n",
      "Test  (+/-): -0.000507\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.86024\n",
      "Test Accuracy: 0.75713\n",
      "Training Time: 34.01s\n",
      "Train (+/-): 0.004432\n",
      "Test  (+/-): 0.003403\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86441\n",
      "Test Accuracy: 0.75013\n",
      "Training Time: 43.19s\n",
      "Train (+/-): 0.000463\n",
      "Test  (+/-): 0.00118\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost, geologic_zone_original)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Geologic_Zone', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Adaboost']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Adaboost']['test_score'], 6))\n",
    "\n",
    "# Extra Trees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees, geologic_zone_original)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Geologic_Zone', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['ExtraTrees']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['ExtraTrees']['test_score'], 6))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging, geologic_zone_original)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Geologic_Zone', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Bagging']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Bagging']['test_score'], 6))\n",
    "\n",
    "# Random Forest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest, geologic_zone_original)\n",
    "\n",
    "random_scores.append((\n",
    "    'Geologic_Zone',  cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['RandomForest']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['RandomForest']['test_score'], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c97d636",
   "metadata": {},
   "source": [
    "## Surface Cover (Ordinal)\n",
    "\n",
    "According to the [USDA reference](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/ref/?cid=nrcs142p2_054253#surface_fragments) on soil profiling:\n",
    "\n",
    "1. **(Stony/Bouldery)** — Stones or boulders cover 0.01 to less than 0.1 percent of the surface. The smallest stones are at least 8 meters apart; the smallest boulders are at least 20 meters apart (fig. 3-9).\n",
    "\n",
    "2. **(Very Stony/Very Bouldery)** — Stones or boulders cover 0.1 to less than 3 percent of the surface. The smallest stones are not less than 1 meter apart; the smallest boulders are not less than 3 meters apart (fig. 3-10).\n",
    "\n",
    "3. **(Extremely Stony/Extremely Bouldery)** — Stones or boulders cover 3 to less than 15 percent of the surface. The smallest stones are as little as 0.5 meter apart; the smallest boulders are as little as 1 meter apart (fig. 3-11).\n",
    "\n",
    "4. **(Rubbly)** — Stones or boulders cover 15 to less than 50 percent of the surface. The smallest stones are as little as 0.3 meter apart; the smallest boulders are as little as 0.5 meter apart. In most places it is possible to step from stone to stone or jump from boulder to boulder without touching the soil (fig. 3-12).\n",
    "\n",
    "5. **(Very Rubbly)** — Stones or boulders appear to be nearly continuous and cover 50 percent or more of the surface. The smallest stones are less than 0.03 meter apart; the smallest boulders are less than 0.05 meter apart. Classifiable soil is among the rock fragments, and plant growth is possible (fig. 3-13)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d6174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_cover_original(input_df):\n",
    "    # Group IDs\n",
    "    no_desc = [7,8,14,15,16,17,19,20,21,23,35]\n",
    "    stony = [6,12]\n",
    "    very_stony = [2,9,18,26]\n",
    "    extremely_stony = [1,22,24,25,27,28,29,30,31,32,33,34,36,37,38,39,40]\n",
    "    rubbly = [3,4,5,10,11,13]\n",
    "\n",
    "    # Create dictionary\n",
    "    surface_cover = {i:0 for i in no_desc}\n",
    "    surface_cover.update({i:1 for i in stony})\n",
    "    surface_cover.update({i:2 for i in very_stony})\n",
    "    surface_cover.update({i:3 for i in extremely_stony})\n",
    "    surface_cover.update({i:4 for i in rubbly})\n",
    "    \n",
    "    # Create Feature\n",
    "    temp_df = categorical_encoding(input_df)\n",
    "    df = input_df.copy()\n",
    "    df['Surface_Cover'] = temp_df['Soil_Type'].apply(lambda x: surface_cover[x])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1efdc8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.7945\n",
      "Test Accuracy: 0.75744\n",
      "Training Time: 5.21s\n",
      "Train (+/-): -0.009062\n",
      "Test  (+/-): 0.003716\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88538\n",
      "Test Accuracy: 0.7782\n",
      "Training Time: 45.44s\n",
      "Train (+/-): 0.000462\n",
      "Test  (+/-): 0.00012\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85627\n",
      "Test Accuracy: 0.75621\n",
      "Training Time: 29.66s\n",
      "Train (+/-): 0.000463\n",
      "Test  (+/-): 0.002485\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86348\n",
      "Test Accuracy: 0.74902\n",
      "Training Time: 38.57s\n",
      "Train (+/-): -0.000463\n",
      "Test  (+/-): 7.2e-05\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost, surface_cover_original)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Surface_Cover', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Adaboost']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Adaboost']['test_score'], 6))\n",
    "\n",
    "# Extra Trees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees, surface_cover_original)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Surface_Cover', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['ExtraTrees']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['ExtraTrees']['test_score'], 6))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging, surface_cover_original)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Surface_Cover', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Bagging']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Bagging']['test_score'], 6))\n",
    "\n",
    "# Random Forest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest, surface_cover_original)\n",
    "\n",
    "random_scores.append((\n",
    "    'Surface_Cover', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['RandomForest']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['RandomForest']['test_score'], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74569c",
   "metadata": {},
   "source": [
    "## Rock Size (Ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "645b48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rock_size_original(input_df):\n",
    "    \n",
    "    # Group IDs\n",
    "    no_desc = [7,8,14,15,16,17,19,20,21,23,35]\n",
    "    stones = [1,2,6,9,12,18,24,25,26,27,28,29,30,31,32,33,34,36,37,38,39,40]\n",
    "    boulders = [22]\n",
    "    rubble = [3,4,5,10,11,13]\n",
    "\n",
    "    # Create dictionary\n",
    "    rock_size = {i:0 for i in no_desc}\n",
    "    rock_size.update({i:1 for i in stones})\n",
    "    rock_size.update({i:2 for i in boulders})\n",
    "    rock_size.update({i:3 for i in rubble})\n",
    "    \n",
    "    temp_df = categorical_encoding(input_df)\n",
    "    df = input_df.copy()\n",
    "    df['Rock_Size'] = temp_df['Soil_Type'].apply(lambda x: rock_size[x])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b12c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoostClassifier\n",
      "Train Accuracy: 0.7943\n",
      "Test Accuracy: 0.75704\n",
      "Training Time: 4.89s\n",
      "Train (+/-): -0.00926\n",
      "Test  (+/-): 0.00331\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.88703\n",
      "Test Accuracy: 0.77801\n",
      "Training Time: 42.13s\n",
      "Train (+/-): 0.002116\n",
      "Test  (+/-): -7.1e-05\n",
      "\n",
      "BaggingClassifier\n",
      "Train Accuracy: 0.85535\n",
      "Test Accuracy: 0.7568\n",
      "Training Time: 30.65s\n",
      "Train (+/-): -0.000463\n",
      "Test  (+/-): 0.00308\n",
      "\n",
      "RandomForestClassifier\n",
      "Train Accuracy: 0.86666\n",
      "Test Accuracy: 0.74992\n",
      "Training Time: 37.38s\n",
      "Train (+/-): 0.002712\n",
      "Test  (+/-): 0.00097\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "cv_score, oof_preds, test_score = train_original(adaboost, rock_size_original)\n",
    "\n",
    "adaboost_scores.append((\n",
    "    'Rock_Size', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Adaboost']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Adaboost']['test_score'], 6))\n",
    "\n",
    "# Extra Trees\n",
    "cv_score, oof_preds, test_score = train_original(extratrees, rock_size_original)\n",
    "\n",
    "extratrees_scores.append((\n",
    "    'Rock_Size', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['ExtraTrees']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['ExtraTrees']['test_score'], 6))\n",
    "\n",
    "# Bagging\n",
    "cv_score, oof_preds, test_score = train_original(bagging, rock_size_original)\n",
    "\n",
    "bagging_scores.append((\n",
    "    'Rock_Size', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['Bagging']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['Bagging']['test_score'], 6))\n",
    "\n",
    "# Random Forest\n",
    "cv_score, oof_preds, test_score = train_original(randomforest, rock_size_original)\n",
    "\n",
    "random_scores.append((\n",
    "    'Rock_Size', cv_score, test_score,\n",
    "     *recall_score(y_train, oof_preds, average = None)\n",
    "))\n",
    "\n",
    "print('Train (+/-):', round(cv_score - baseline['RandomForest']['cv_score'], 6))\n",
    "print('Test  (+/-):', round(test_score - baseline['RandomForest']['test_score'], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8960be5",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "All of these features seem promising, so we won't rule any out just yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a621a85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>holdout</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>recall_3</th>\n",
       "      <th>recall_4</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.803559</td>\n",
       "      <td>0.753727</td>\n",
       "      <td>0.681944</td>\n",
       "      <td>0.650463</td>\n",
       "      <td>0.745716</td>\n",
       "      <td>0.926389</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.791204</td>\n",
       "      <td>0.935648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Climatic_Zone</td>\n",
       "      <td>0.800979</td>\n",
       "      <td>0.759695</td>\n",
       "      <td>0.665741</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.755442</td>\n",
       "      <td>0.943056</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.782870</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geologic_Zone</td>\n",
       "      <td>0.796414</td>\n",
       "      <td>0.753588</td>\n",
       "      <td>0.682407</td>\n",
       "      <td>0.630093</td>\n",
       "      <td>0.732747</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.893519</td>\n",
       "      <td>0.780556</td>\n",
       "      <td>0.930556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surface_Cover</td>\n",
       "      <td>0.794497</td>\n",
       "      <td>0.757444</td>\n",
       "      <td>0.674537</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.739231</td>\n",
       "      <td>0.928704</td>\n",
       "      <td>0.890278</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.922685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rock_Size</td>\n",
       "      <td>0.794299</td>\n",
       "      <td>0.757037</td>\n",
       "      <td>0.665278</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.753126</td>\n",
       "      <td>0.943981</td>\n",
       "      <td>0.886574</td>\n",
       "      <td>0.764815</td>\n",
       "      <td>0.924074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.785965</td>\n",
       "      <td>0.762291</td>\n",
       "      <td>0.674537</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.723020</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.878704</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.924074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  cv_score   holdout  recall_0  recall_1  recall_2  recall_3  \\\n",
       "0       Baseline  0.803559  0.753727  0.681944  0.650463  0.745716  0.926389   \n",
       "2  Climatic_Zone  0.800979  0.759695  0.665741  0.622222  0.755442  0.943056   \n",
       "3  Geologic_Zone  0.796414  0.753588  0.682407  0.630093  0.732747  0.925000   \n",
       "4  Surface_Cover  0.794497  0.757444  0.674537  0.637500  0.739231  0.928704   \n",
       "5      Rock_Size  0.794299  0.757037  0.665278  0.622222  0.753126  0.943981   \n",
       "1    Categorical  0.785965  0.762291  0.674537  0.637500  0.723020  0.918519   \n",
       "\n",
       "   recall_4  recall_5  recall_6  \n",
       "0  0.893519  0.791204  0.935648  \n",
       "2  0.900000  0.782870  0.937500  \n",
       "3  0.893519  0.780556  0.930556  \n",
       "4  0.890278  0.768519  0.922685  \n",
       "5  0.886574  0.764815  0.924074  \n",
       "1  0.878704  0.745370  0.924074  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost\n",
    "pd.DataFrame.from_records(\n",
    "    data = adaboost_scores,\n",
    "    columns = ['features','cv_score','holdout','recall_0', 'recall_1','recall_2','recall_3','recall_4','recall_5','recall_6']\n",
    ").sort_values('cv_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34e025cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>holdout</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>recall_3</th>\n",
       "      <th>recall_4</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geologic_Zone</td>\n",
       "      <td>0.887626</td>\n",
       "      <td>0.777571</td>\n",
       "      <td>0.781481</td>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.864752</td>\n",
       "      <td>0.973148</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.973611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rock_Size</td>\n",
       "      <td>0.887030</td>\n",
       "      <td>0.778008</td>\n",
       "      <td>0.782407</td>\n",
       "      <td>0.747685</td>\n",
       "      <td>0.866605</td>\n",
       "      <td>0.973148</td>\n",
       "      <td>0.960648</td>\n",
       "      <td>0.906481</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Climatic_Zone</td>\n",
       "      <td>0.886832</td>\n",
       "      <td>0.780755</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.742593</td>\n",
       "      <td>0.868458</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.961111</td>\n",
       "      <td>0.905093</td>\n",
       "      <td>0.973148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.885377</td>\n",
       "      <td>0.782060</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.861510</td>\n",
       "      <td>0.971759</td>\n",
       "      <td>0.961111</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.972685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surface_Cover</td>\n",
       "      <td>0.885377</td>\n",
       "      <td>0.778198</td>\n",
       "      <td>0.785648</td>\n",
       "      <td>0.741204</td>\n",
       "      <td>0.860120</td>\n",
       "      <td>0.971296</td>\n",
       "      <td>0.959259</td>\n",
       "      <td>0.906944</td>\n",
       "      <td>0.973148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.884914</td>\n",
       "      <td>0.778078</td>\n",
       "      <td>0.786574</td>\n",
       "      <td>0.734259</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.971759</td>\n",
       "      <td>0.961111</td>\n",
       "      <td>0.903704</td>\n",
       "      <td>0.970833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  cv_score   holdout  recall_0  recall_1  recall_2  recall_3  \\\n",
       "3  Geologic_Zone  0.887626  0.777571  0.781481  0.745370  0.864752  0.973148   \n",
       "5      Rock_Size  0.887030  0.778008  0.782407  0.747685  0.866605  0.973148   \n",
       "2  Climatic_Zone  0.886832  0.780755  0.785185  0.742593  0.868458  0.972222   \n",
       "1    Categorical  0.885377  0.782060  0.787500  0.737500  0.861510  0.971759   \n",
       "4  Surface_Cover  0.885377  0.778198  0.785648  0.741204  0.860120  0.971296   \n",
       "0       Baseline  0.884914  0.778078  0.786574  0.734259  0.866142  0.971759   \n",
       "\n",
       "   recall_4  recall_5  recall_6  \n",
       "3  0.962500  0.912500  0.973611  \n",
       "5  0.960648  0.906481  0.972222  \n",
       "2  0.961111  0.905093  0.973148  \n",
       "1  0.961111  0.905556  0.972685  \n",
       "4  0.959259  0.906944  0.973148  \n",
       "0  0.961111  0.903704  0.970833  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "pd.DataFrame.from_records(\n",
    "    data = extratrees_scores,\n",
    "    columns = ['features','cv_score','holdout','recall_0', 'recall_1','recall_2','recall_3','recall_4','recall_5','recall_6']\n",
    ").sort_values('cv_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "768b0342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>holdout</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>recall_3</th>\n",
       "      <th>recall_4</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geologic_Zone</td>\n",
       "      <td>0.860243</td>\n",
       "      <td>0.757127</td>\n",
       "      <td>0.781481</td>\n",
       "      <td>0.685648</td>\n",
       "      <td>0.841130</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.938426</td>\n",
       "      <td>0.851389</td>\n",
       "      <td>0.960648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surface_Cover</td>\n",
       "      <td>0.856274</td>\n",
       "      <td>0.756208</td>\n",
       "      <td>0.774537</td>\n",
       "      <td>0.674537</td>\n",
       "      <td>0.841130</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.855812</td>\n",
       "      <td>0.753724</td>\n",
       "      <td>0.769907</td>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.837888</td>\n",
       "      <td>0.964352</td>\n",
       "      <td>0.934259</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.963426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rock_Size</td>\n",
       "      <td>0.855348</td>\n",
       "      <td>0.756804</td>\n",
       "      <td>0.769907</td>\n",
       "      <td>0.673148</td>\n",
       "      <td>0.841593</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.941204</td>\n",
       "      <td>0.843981</td>\n",
       "      <td>0.955093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Climatic_Zone</td>\n",
       "      <td>0.854687</td>\n",
       "      <td>0.758230</td>\n",
       "      <td>0.774074</td>\n",
       "      <td>0.659259</td>\n",
       "      <td>0.839741</td>\n",
       "      <td>0.964352</td>\n",
       "      <td>0.940741</td>\n",
       "      <td>0.849074</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.850057</td>\n",
       "      <td>0.759820</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.819824</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.830556</td>\n",
       "      <td>0.954630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  cv_score   holdout  recall_0  recall_1  recall_2  recall_3  \\\n",
       "3  Geologic_Zone  0.860243  0.757127  0.781481  0.685648  0.841130  0.962963   \n",
       "4  Surface_Cover  0.856274  0.756208  0.774537  0.674537  0.841130  0.963889   \n",
       "0       Baseline  0.855812  0.753724  0.769907  0.670833  0.837888  0.964352   \n",
       "5      Rock_Size  0.855348  0.756804  0.769907  0.673148  0.841593  0.962500   \n",
       "2  Climatic_Zone  0.854687  0.758230  0.774074  0.659259  0.839741  0.964352   \n",
       "1    Categorical  0.850057  0.759820  0.775000  0.672222  0.819824  0.958333   \n",
       "\n",
       "   recall_4  recall_5  recall_6  \n",
       "3  0.938426  0.851389  0.960648  \n",
       "4  0.939815  0.844444  0.955556  \n",
       "0  0.934259  0.850000  0.963426  \n",
       "5  0.941204  0.843981  0.955093  \n",
       "2  0.940741  0.849074  0.955556  \n",
       "1  0.939815  0.830556  0.954630  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging Classifier\n",
    "pd.DataFrame.from_records(\n",
    "    data = bagging_scores,\n",
    "    columns = ['features','cv_score','holdout','recall_0', 'recall_1','recall_2','recall_3','recall_4','recall_5','recall_6']\n",
    ").sort_values('cv_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d892bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>holdout</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>recall_3</th>\n",
       "      <th>recall_4</th>\n",
       "      <th>recall_5</th>\n",
       "      <th>recall_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rock_Size</td>\n",
       "      <td>0.866658</td>\n",
       "      <td>0.749919</td>\n",
       "      <td>0.768981</td>\n",
       "      <td>0.710185</td>\n",
       "      <td>0.821214</td>\n",
       "      <td>0.971759</td>\n",
       "      <td>0.949074</td>\n",
       "      <td>0.877315</td>\n",
       "      <td>0.968056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.864542</td>\n",
       "      <td>0.748216</td>\n",
       "      <td>0.765741</td>\n",
       "      <td>0.695370</td>\n",
       "      <td>0.824456</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.871759</td>\n",
       "      <td>0.968056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geologic_Zone</td>\n",
       "      <td>0.864409</td>\n",
       "      <td>0.750129</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.817508</td>\n",
       "      <td>0.969907</td>\n",
       "      <td>0.949074</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.963426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Climatic_Zone</td>\n",
       "      <td>0.864079</td>\n",
       "      <td>0.748825</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.701852</td>\n",
       "      <td>0.823993</td>\n",
       "      <td>0.971759</td>\n",
       "      <td>0.951852</td>\n",
       "      <td>0.867593</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.863947</td>\n",
       "      <td>0.748949</td>\n",
       "      <td>0.767593</td>\n",
       "      <td>0.701852</td>\n",
       "      <td>0.819824</td>\n",
       "      <td>0.971759</td>\n",
       "      <td>0.950926</td>\n",
       "      <td>0.869444</td>\n",
       "      <td>0.966204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surface_Cover</td>\n",
       "      <td>0.863484</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.696759</td>\n",
       "      <td>0.823066</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.950926</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.967130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  cv_score   holdout  recall_0  recall_1  recall_2  recall_3  \\\n",
       "5      Rock_Size  0.866658  0.749919  0.768981  0.710185  0.821214  0.971759   \n",
       "1    Categorical  0.864542  0.748216  0.765741  0.695370  0.824456  0.970833   \n",
       "3  Geologic_Zone  0.864409  0.750129  0.772222  0.708333  0.817508  0.969907   \n",
       "2  Climatic_Zone  0.864079  0.748825  0.768519  0.701852  0.823993  0.971759   \n",
       "0       Baseline  0.863947  0.748949  0.767593  0.701852  0.819824  0.971759   \n",
       "4  Surface_Cover  0.863484  0.749021  0.763889  0.696759  0.823066  0.972222   \n",
       "\n",
       "   recall_4  recall_5  recall_6  \n",
       "5  0.949074  0.877315  0.968056  \n",
       "1  0.955556  0.871759  0.968056  \n",
       "3  0.949074  0.870370  0.963426  \n",
       "2  0.951852  0.867593  0.962963  \n",
       "0  0.950926  0.869444  0.966204  \n",
       "4  0.950926  0.870370  0.967130  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "pd.DataFrame.from_records(\n",
    "    data = random_scores,\n",
    "    columns = ['features','cv_score','holdout','recall_0', 'recall_1','recall_2','recall_3','recall_4','recall_5','recall_6']\n",
    ").sort_values('cv_score', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
