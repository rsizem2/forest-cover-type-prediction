{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68af42ae",
   "metadata": {},
   "source": [
    "# Notebook 5 - Feature Importance\n",
    "\n",
    "In this notebook, we check the feature importances using permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f56aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for testing changes to this notebook quickly\n",
    "RANDOM_SEED = 0\n",
    "NUM_FOLDS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b423bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "import time\n",
    "import pyarrow\n",
    "import gc\n",
    "\n",
    "# Model evaluation\n",
    "from functools import partial\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.inspection import partial_dependence, permutation_importance\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5744397",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7523315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load original data\n",
    "original = pd.read_feather('../data/original.feather')\n",
    "\n",
    "# Label Encode\n",
    "old_encoder = LabelEncoder()\n",
    "original[\"Cover_Type\"] = old_encoder.fit_transform(original[\"Cover_Type\"])\n",
    "y_train = original['Cover_Type'].iloc[:15119]\n",
    "y_test = original['Cover_Type'].iloc[15119:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fc040",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb266ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Get columns\n",
    "    shade_features = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n",
    "    soil_features = [f'Soil_Type{i}' for i in range(1,41)]\n",
    "    \n",
    "    \n",
    "    # Use float64 for calculations\n",
    "    for col, dtype in df.dtypes.iteritems():\n",
    "        if dtype.name.startswith('float'):\n",
    "            df[col] = df[col].astype('float64')\n",
    "    \n",
    "    # Replace soil type columns with categoricals\n",
    "    df['Soil_Type'] = 0\n",
    "    for i in range(1,41):\n",
    "        df['Soil_Type'] += i*df[f'Soil_Type{i}']\n",
    "        \n",
    "        \n",
    "    df['Soil_12_32'] = df['Soil_Type32'] + df['Soil_Type12']\n",
    "    df['Soil_Type23_22_32_33'] = df['Soil_Type23'] + df['Soil_Type22'] + df['Soil_Type32'] + df['Soil_Type33']\n",
    "    #df['Aspect_360'] = df['Aspect'] % 360\n",
    "    #df['Aspect_Sine'] = (df['Aspect']* np.pi / 180).apply(np.sin)\n",
    "    #df['Aspect_Alt'] = (df['Aspect']-180).where(df['Aspect']+180 > 360, df['Aspect'] + 180)\n",
    "    df['Horizontal_Distance_To_Roadways_Log'] = [math.log(v+1) for v in df['Horizontal_Distance_To_Roadways']]\n",
    "    #df['Horizontal_Distance_To_Hydrology_Log'] = [math.log(v+1) for v in df['Horizontal_Distance_To_Hydrology']]\n",
    "    #df['Elev_Binned'] = [math.floor(v/50.0) for v in df['Elevation']]\n",
    "    #df[\"Hydro_Taxicab\"] = np.abs(df[\"Horizontal_Distance_To_Hydrology\"]) + np.abs(df[\"Vertical_Distance_To_Hydrology\"])\n",
    "    #df[\"Hydro_Euclid\"] = (df[\"Horizontal_Distance_To_Hydrology\"]**2 + np.abs(df[\"Vertical_Distance_To_Hydrology\"])**2)**0.5\n",
    "    #df['Water_Direction'] = df['Vertical_Distance_To_Hydrology'].apply(np.sign)\n",
    "    df['Water Elevation'] = df['Elevation'] - df['Vertical_Distance_To_Hydrology']\n",
    "    #df[\"Hillshade_Avg\"] = df[shade_features].mean(axis=1)\n",
    "    #df['Hillshade_Range'] = df[shade_features].max(axis=1) - df[shade_features].min(axis=1)\n",
    "    #df['Hillshade'] = df[shade_features].sum(axis=1)\n",
    "    df['Hydro_Fire_1'] = df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Fire_Points']\n",
    "    df['Hydro_Fire_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Fire_Points'])\n",
    "    df['Hydro_Road_1'] = abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Hydro_Road_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Fire_Road_1'] = abs(df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Roadways'])\n",
    "    df['Fire_Road_2'] = abs(df['Horizontal_Distance_To_Fire_Points'] - df['Horizontal_Distance_To_Roadways'])\n",
    "    #df['EHiElv'] = df['Horizontal_Distance_To_Roadways'] * df['Elevation']\n",
    "    #df['EViElv'] = df['Vertical_Distance_To_Hydrology'] * df['Elevation']\n",
    "    df['EVDtH'] = df.Elevation - df.Vertical_Distance_To_Hydrology\n",
    "    #df['EHDtH'] = df.Elevation - df.Horizontal_Distance_To_Hydrology * 0.2\n",
    "    df['Elev_3Horiz'] = df['Elevation'] + df['Horizontal_Distance_To_Roadways']  + df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Hydrology']\n",
    "    df['Elev_Road_1'] = df['Elevation'] + df['Horizontal_Distance_To_Roadways']\n",
    "    df['Elev_Road_2'] = df['Elevation'] - df['Horizontal_Distance_To_Roadways']\n",
    "    df['Elev_Fire_1'] = df['Elevation'] + df['Horizontal_Distance_To_Fire_Points']\n",
    "    df['Elev_Fire_2'] = df['Elevation'] - df['Horizontal_Distance_To_Fire_Points']\n",
    "    #df['Elev_Hillshade_1'] = df['Elevation'] - df['Hillshade']\n",
    "    #df['Elev_Hillshade_2'] = df['Elevation'] + df['Hillshade']\n",
    "    \n",
    "    # ELU soil codes\n",
    "    code = {\n",
    "        1:2702,2:2703,3:2704,4:2705,5:2706,6:2717,7:3501,8:3502,9:4201,\n",
    "        10:4703,11:4704,12:4744,13:4758,14:5101,15:5151,16:6101,17:6102,\n",
    "        18:6731,19:7101,20:7102,21:7103,22:7201,23:7202,24:7700,25:7701,\n",
    "        26:7702,27:7709,28:7710,29:7745,30:7746,31:7755,32:7756,33:7757,\n",
    "        34:7790,35:8703,36:8707,37:8708,38:8771,39:8772,40:8776\n",
    "    }\n",
    "    \n",
    "    # Climatic Zone\n",
    "    df['Climatic_Zone'] = df['Soil_Type'].apply(lambda x: int(str(code[x])[0]))\n",
    "    \n",
    "    # Geologic Zone\n",
    "    df['Geologic_Zone'] = df['Soil_Type'].apply(lambda x: int(str(code[x])[1]))\n",
    "    \n",
    "    # Surface Cover\n",
    "    no_desc = [7,8,14,15,16,17,19,20,21,23,35]\n",
    "    stony = [6,12]\n",
    "    very_stony = [2,9,18,26]\n",
    "    extremely_stony = [1,22,24,25,27,28,29,30,31,32,33,34,36,37,38,39,40]\n",
    "    rubbly = [3,4,5,10,11,13]\n",
    "    surface_cover = {i:0 for i in no_desc}\n",
    "    surface_cover.update({i:1 for i in stony})\n",
    "    surface_cover.update({i:2 for i in very_stony})\n",
    "    surface_cover.update({i:3 for i in extremely_stony})\n",
    "    surface_cover.update({i:4 for i in rubbly})\n",
    "    \n",
    "    df['Surface_Cover'] = df['Soil_Type'].apply(lambda x: surface_cover[x])\n",
    "\n",
    "    # Rock Size\n",
    "    no_desc = [7,8,14,15,16,17,19,20,21,23,35]\n",
    "    stones = [1,2,6,9,12,18,24,25,26,27,28,29,30,31,32,33,34,36,37,38,39,40]\n",
    "    boulders = [22]\n",
    "    rubble = [3,4,5,10,11,13]\n",
    "    rock_size = {i:0 for i in no_desc}\n",
    "    rock_size.update({i:1 for i in stones})\n",
    "    rock_size.update({i:2 for i in boulders})\n",
    "    rock_size.update({i:3 for i in rubble})\n",
    "    \n",
    "    df['Rock_Size'] = df['Soil_Type'].apply(lambda x: rock_size[x])\n",
    "\n",
    "            \n",
    "    # Wilderness Interactions\n",
    "    df['Climate_Area1'] = df['Wilderness_Area1']*df['Climatic_Zone'] \n",
    "    df['Climate_Area2'] = df['Wilderness_Area2']*df['Climatic_Zone'] \n",
    "    df['Climate_Area3'] = df['Wilderness_Area3']*df['Climatic_Zone'] \n",
    "    df['Climate_Area4'] = df['Wilderness_Area4']*df['Climatic_Zone'] \n",
    "    #df['Geologic_Area1'] = df['Wilderness_Area1']*df['Geologic_Zone'] \n",
    "    #df['Geologic_Area2'] = df['Wilderness_Area2']*df['Geologic_Zone']  \n",
    "    #df['Geologic_Area3'] = df['Wilderness_Area3']*df['Geologic_Zone'] \n",
    "    #df['Geologic_Area4'] = df['Wilderness_Area4']*df['Geologic_Zone'] \n",
    "    df['Rock_Area1'] = df['Wilderness_Area1']*df['Rock_Size'] \n",
    "    df['Rock_Area2'] = df['Wilderness_Area2']*df['Rock_Size']   \n",
    "    df['Rock_Area3'] = df['Wilderness_Area3']*df['Rock_Size']  \n",
    "    df['Rock_Area4'] = df['Wilderness_Area4']*df['Rock_Size']\n",
    "    df['Surface_Area1'] = df['Wilderness_Area1']*df['Surface_Cover'] \n",
    "    df['Surface_Area2'] = df['Wilderness_Area2']*df['Surface_Cover']   \n",
    "    df['Surface_Area3'] = df['Wilderness_Area3']*df['Surface_Cover']  \n",
    "    df['Surface_Area4'] = df['Wilderness_Area4']*df['Surface_Cover'] \n",
    "    df['Soil29_Area1'] = df['Soil_Type29'] + df['Wilderness_Area1']\n",
    "    df['Soil3_Area4'] = df['Wilderness_Area4'] + df['Soil_Type3']\n",
    "    \n",
    "    # Drop redundant Soil columns\n",
    "    df.drop(soil_features, axis = 1, inplace = True)\n",
    "    \n",
    "    # Fill NA\n",
    "    df.fillna(0, inplace = True)\n",
    "    \n",
    "    # Downcast variables\n",
    "    for col, dtype in df.dtypes.iteritems():\n",
    "        if dtype.name.startswith('int'):\n",
    "            df[col] = pd.to_numeric(df[col], downcast ='integer')\n",
    "        elif dtype.name.startswith('float'):\n",
    "            df[col] = pd.to_numeric(df[col], downcast ='float')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7110614b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "original = feature_engineering(original)\n",
    "\n",
    "# Get feature columns\n",
    "features = [x for x in original.columns if x not in ['Id','Cover_Type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6164f26",
   "metadata": {},
   "source": [
    "# Training/Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceaaecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_original(sklearn_model):\n",
    "    \n",
    "    # Train/Test split\n",
    "    X_temp = original[features].iloc[:15119]\n",
    "    X_test = original[features].iloc[15119:]\n",
    "    y_temp = original['Cover_Type'].iloc[:15119]\n",
    "    y_test = original['Cover_Type'].iloc[15119:]\n",
    "    \n",
    "    # Store the out-of-fold predictions\n",
    "    test_preds = np.zeros((X_test.shape[0],7))\n",
    "    oof_preds = np.zeros((X_temp.shape[0],))\n",
    "    fi_scores = np.zeros((X_temp.shape[1],))\n",
    "    scores, times = np.zeros(NUM_FOLDS), np.zeros(NUM_FOLDS)\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X_temp,y_temp)):\n",
    "       \n",
    "        # Training and Validation Sets\n",
    "        X_train, X_valid = X_temp.iloc[train_idx], X_temp.iloc[valid_idx]\n",
    "        y_train, y_valid = y_temp.iloc[train_idx], y_temp.iloc[valid_idx]\n",
    "        \n",
    "        # Create model\n",
    "        start = time.time()\n",
    "        model = clone(sklearn_model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Permutation Importance\n",
    "        result = permutation_importance(\n",
    "            model, X_valid, y_valid, \n",
    "            n_repeats=5, random_state=RANDOM_SEED, n_jobs=-1\n",
    "        )\n",
    "        fi_scores += result.importances_mean / NUM_FOLDS\n",
    "\n",
    "        # validation/holdout predictions\n",
    "        valid_preds = np.ravel(model.predict(X_valid))\n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "        test_preds += model.predict_proba(X_test)\n",
    "\n",
    "        # Save scores and times\n",
    "        scores[fold] = accuracy_score(y_valid, valid_preds)\n",
    "        end = time.time()\n",
    "        times[fold] = end-start\n",
    "        print(f'Fold {fold}: {round(scores[fold], 5)} in {round(times[fold], 2)}s')\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    test_preds = np.argmax(test_preds, axis = 1)\n",
    "    test_score = accuracy_score(y_test, test_preds)\n",
    "    print('\\n'+model.__class__.__name__)\n",
    "    print(\"Train Accuracy:\", round(scores.mean(), 5))\n",
    "    print('Test Accuracy:', round(test_score, 5))\n",
    "    print(f'Training Time: {round(times.sum(), 2)}s')\n",
    "    \n",
    "    return pd.Series(data = fi_scores, index = features).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfb048",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712ba802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extremely Randomized Trees\n",
    "extratrees = ExtraTreesClassifier(\n",
    "    n_jobs = -1,\n",
    "    random_state = RANDOM_SEED,\n",
    "    max_features = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce59013a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 0.90873 in 20.17s\n",
      "Fold 1: 0.91508 in 15.65s\n",
      "Fold 2: 0.9 in 15.11s\n",
      "Fold 3: 0.90556 in 15.4s\n",
      "Fold 4: 0.89921 in 16.01s\n",
      "Fold 5: 0.91349 in 19.75s\n",
      "Fold 6: 0.91111 in 19.59s\n",
      "Fold 7: 0.90714 in 15.38s\n",
      "Fold 8: 0.89921 in 15.16s\n",
      "Fold 9: 0.91667 in 15.24s\n",
      "Fold 10: 0.90794 in 15.51s\n",
      "Fold 11: 0.91581 in 14.61s\n",
      "\n",
      "ExtraTreesClassifier\n",
      "Train Accuracy: 0.90833\n",
      "Test Accuracy: 0.81348\n",
      "Training Time: 197.58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Climate_Area1                         -0.000238\n",
       "Surface_Area4                          0.000027\n",
       "Surface_Area2                          0.000079\n",
       "Rock_Area3                             0.000093\n",
       "Rock_Area2                             0.000093\n",
       "Wilderness_Area1                       0.000119\n",
       "Wilderness_Area3                       0.000172\n",
       "Rock_Area4                             0.000172\n",
       "Climate_Area4                          0.000371\n",
       "Surface_Area3                          0.000463\n",
       "Wilderness_Area2                       0.000503\n",
       "Rock_Size                              0.000556\n",
       "Climate_Area2                          0.000701\n",
       "Surface_Area1                          0.000754\n",
       "Rock_Area1                             0.000926\n",
       "Soil_12_32                             0.001032\n",
       "Climate_Area3                          0.001032\n",
       "Surface_Cover                          0.001416\n",
       "Horizontal_Distance_To_Roadways_Log    0.001455\n",
       "Hillshade_3pm                          0.001482\n",
       "Slope                                  0.001680\n",
       "Hydro_Road_1                           0.001746\n",
       "Soil29_Area1                           0.002156\n",
       "Elev_Road_1                            0.002408\n",
       "Hydro_Fire_1                           0.002527\n",
       "Elev_3Horiz                            0.002646\n",
       "Horizontal_Distance_To_Roadways        0.002738\n",
       "Elev_Fire_1                            0.002871\n",
       "Elev_Road_2                            0.002950\n",
       "Horizontal_Distance_To_Fire_Points     0.003056\n",
       "Elev_Fire_2                            0.003175\n",
       "Hydro_Road_2                           0.003373\n",
       "Hydro_Fire_2                           0.003849\n",
       "Geologic_Zone                          0.003903\n",
       "Wilderness_Area4                       0.003916\n",
       "Soil_Type23_22_32_33                   0.004048\n",
       "Vertical_Distance_To_Hydrology         0.004141\n",
       "Fire_Road_1                            0.005754\n",
       "Aspect                                 0.005887\n",
       "Soil_Type                              0.006310\n",
       "Hillshade_Noon                         0.007884\n",
       "Fire_Road_2                            0.010239\n",
       "Hillshade_9am                          0.011191\n",
       "Climatic_Zone                          0.012250\n",
       "Soil3_Area4                            0.031312\n",
       "EVDtH                                  0.034064\n",
       "Horizontal_Distance_To_Hydrology       0.037106\n",
       "Water Elevation                        0.042410\n",
       "Elevation                              0.056567\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_original(extratrees)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
